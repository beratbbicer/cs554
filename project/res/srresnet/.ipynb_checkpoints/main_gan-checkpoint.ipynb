{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import nn\n",
    "from models import Generator, Discriminator, TruncatedVGG19\n",
    "from datasets import SRDataset\n",
    "from dataset import LowDataset\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Data parameters\n",
    "data_folder = 'data'\n",
    "crop_size = 96  # crop size of target HR images\n",
    "scaling_factor = 2  # the scaling factor for the generator; the input LR images will be downsampled from the target HR images by this factor\n",
    "\n",
    "# Generator parameters\n",
    "large_kernel_size_g = 9  # kernel size of the first and last convolutions which transform the inputs and outputs\n",
    "small_kernel_size_g = 3  # kernel size of all convolutions in-between, i.e. those in the residual and subpixel convolutional blocks\n",
    "n_channels_g = 64  # number of channels in-between, i.e. the input and output channels for the residual and subpixel convolutional blocks\n",
    "n_blocks_g = 16  # number of residual blocks\n",
    "srresnet_checkpoint = None#\"./checkpoint_srresnet.pth.tar\"  # filepath of the trained SRResNet checkpoint used for initialization\n",
    "\n",
    "# Discriminator parameters\n",
    "kernel_size_d = 3  # kernel size in all convolutional blocks\n",
    "n_channels_d = 64  # number of output channels in the first convolutional block, after which it is doubled in every 2nd block thereafter\n",
    "n_blocks_d = 8  # number of convolutional blocks\n",
    "fc_size_d = 1024  # size of the first fully connected layer\n",
    "\n",
    "# Learning parameters\n",
    "checkpoint = None  # path to model (SRGAN) checkpoint, None if none\n",
    "batch_size = 16  # batch size\n",
    "start_epoch = 0  # start at this epoch\n",
    "iterations = 2e5  # number of training iterations\n",
    "workers = 4  # number of workers for loading data in the DataLoader\n",
    "vgg19_i = 5  # the index i in the definition for VGG loss; see paper or models.py\n",
    "vgg19_j = 4  # the index j in the definition for VGG loss; see paper or models.py\n",
    "beta = 1e-3  # the coefficient to weight the adversarial loss in the perceptual loss\n",
    "print_freq = 4  # print training status once every __ batches\n",
    "lr = 1e-4  # learning rate\n",
    "grad_clip = None  # clip if gradients are exploding\n",
    "\n",
    "# Default device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cudnn.benchmark = True\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, generator, discriminator, truncated_vgg19, content_loss_criterion, adversarial_loss_criterion,\n",
    "          optimizer_g, optimizer_d, epoch):\n",
    "    \"\"\"\n",
    "    One epoch's training.\n",
    "    :param train_loader: train dataloader\n",
    "    :param generator: generator\n",
    "    :param discriminator: discriminator\n",
    "    :param truncated_vgg19: truncated VGG19 network\n",
    "    :param content_loss_criterion: content loss function (Mean Squared-Error loss)\n",
    "    :param adversarial_loss_criterion: adversarial loss function (Binary Cross-Entropy loss)\n",
    "    :param optimizer_g: optimizer for the generator\n",
    "    :param optimizer_d: optimizer for the discriminator\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "    # Set to train mode\n",
    "    generator.train()\n",
    "    discriminator.train()  # training mode enables batch normalization\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses_c = AverageMeter()  # content loss\n",
    "    losses_a = AverageMeter()  # adversarial loss in the generator\n",
    "    losses_d = AverageMeter()  # adversarial loss in the discriminator\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Batches\n",
    "    for i, (lr_imgs, hr_imgs) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to default device\n",
    "        lr_imgs = lr_imgs.to(device)  # (batch_size (N), 3, 24, 24), imagenet-normed\n",
    "        hr_imgs = hr_imgs.to(device)  # (batch_size (N), 3, 96, 96), imagenet-normed\n",
    "\n",
    "        # GENERATOR UPDATE\n",
    "\n",
    "        # Generate\n",
    "        sr_imgs = generator(lr_imgs)  # (N, 3, 96, 96), in [-1, 1]\n",
    "        sr_imgs = convert_image(sr_imgs, source='[-1, 1]', target='imagenet-norm')  # (N, 3, 96, 96), imagenet-normed\n",
    "\n",
    "        # Calculate VGG feature maps for the super-resolved (SR) and high resolution (HR) images\n",
    "        sr_imgs_in_vgg_space = truncated_vgg19(sr_imgs)\n",
    "        hr_imgs_in_vgg_space = truncated_vgg19(hr_imgs).detach()  # detached because they're constant, targets\n",
    "\n",
    "        # Discriminate super-resolved (SR) images\n",
    "        sr_discriminated = discriminator(sr_imgs)  # (N)\n",
    "\n",
    "        # Calculate the Perceptual loss\n",
    "        content_loss = content_loss_criterion(sr_imgs_in_vgg_space, hr_imgs_in_vgg_space)\n",
    "        adversarial_loss = adversarial_loss_criterion(sr_discriminated, torch.ones_like(sr_discriminated))\n",
    "        perceptual_loss = content_loss + beta * adversarial_loss\n",
    "\n",
    "        # Back-prop.\n",
    "        optimizer_g.zero_grad()\n",
    "        perceptual_loss.backward()\n",
    "\n",
    "        # Clip gradients, if necessary\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(optimizer_g, grad_clip)\n",
    "\n",
    "        # Update generator\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # Keep track of loss\n",
    "        losses_c.update(content_loss.item(), lr_imgs.size(0))\n",
    "        losses_a.update(adversarial_loss.item(), lr_imgs.size(0))\n",
    "\n",
    "        # DISCRIMINATOR UPDATE\n",
    "\n",
    "        # Discriminate super-resolution (SR) and high-resolution (HR) images\n",
    "        hr_discriminated = discriminator(hr_imgs)\n",
    "        sr_discriminated = discriminator(sr_imgs.detach())\n",
    "        # But didn't we already discriminate the SR images earlier, before updating the generator (G)? Why not just use that here?\n",
    "        # Because, if we used that, we'd be back-propagating (finding gradients) over the G too when backward() is called\n",
    "        # It's actually faster to detach the SR images from the G and forward-prop again, than to back-prop. over the G unnecessarily\n",
    "        # See FAQ section in the tutorial\n",
    "\n",
    "        # Binary Cross-Entropy loss\n",
    "        adversarial_loss = adversarial_loss_criterion(sr_discriminated, torch.zeros_like(sr_discriminated)) + \\\n",
    "                           adversarial_loss_criterion(hr_discriminated, torch.ones_like(hr_discriminated))\n",
    "\n",
    "        # Back-prop.\n",
    "        optimizer_d.zero_grad()\n",
    "        adversarial_loss.backward()\n",
    "\n",
    "        # Clip gradients, if necessary\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(optimizer_d, grad_clip)\n",
    "\n",
    "        # Update discriminator\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Keep track of loss\n",
    "        losses_d.update(adversarial_loss.item(), hr_imgs.size(0))\n",
    "\n",
    "        # Keep track of batch times\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        # Reset start time\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]----'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})----'\n",
    "                  'Data Time {data_time.val:.3f} ({data_time.avg:.3f})----'\n",
    "                  'Cont. Loss {loss_c.val:.4f} ({loss_c.avg:.4f})----'\n",
    "                  'Adv. Loss {loss_a.val:.4f} ({loss_a.avg:.4f})----'\n",
    "                  'Disc. Loss {loss_d.val:.4f} ({loss_d.avg:.4f})'.format(epoch,\n",
    "                                                                          i,\n",
    "                                                                          len(train_loader),\n",
    "                                                                          batch_time=batch_time,\n",
    "                                                                          data_time=data_time,\n",
    "                                                                          loss_c=losses_c,\n",
    "                                                                          loss_a=losses_a,\n",
    "                                                                          loss_d=losses_d))\n",
    "\n",
    "    del lr_imgs, hr_imgs, sr_imgs, hr_imgs_in_vgg_space, sr_imgs_in_vgg_space, hr_discriminated, sr_discriminated  # free some memory since their histories may be store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Training.\n",
    "    \"\"\"\n",
    "    global start_epoch, epoch, checkpoint, srresnet_checkpoint\n",
    "\n",
    "    # Initialize model or load checkpoint\n",
    "    if checkpoint is None:\n",
    "        # Generator\n",
    "        generator = Generator(large_kernel_size=large_kernel_size_g,\n",
    "                              small_kernel_size=small_kernel_size_g,\n",
    "                              n_channels=n_channels_g,\n",
    "                              n_blocks=n_blocks_g,\n",
    "                              scaling_factor=scaling_factor)\n",
    "\n",
    "        # Initialize generator network with pretrained SRResNet\n",
    "        if srresnet_checkpoint is not None:\n",
    "            generator.initialize_with_srresnet(srresnet_checkpoint=srresnet_checkpoint)\n",
    "\n",
    "        # Initialize generator's optimizer\n",
    "        optimizer_g = torch.optim.Adam(params=filter(lambda p: p.requires_grad, generator.parameters()),\n",
    "                                       lr=lr)\n",
    "\n",
    "        # Discriminator\n",
    "        discriminator = Discriminator(kernel_size=kernel_size_d,\n",
    "                                      n_channels=n_channels_d,\n",
    "                                      n_blocks=n_blocks_d,\n",
    "                                      fc_size=fc_size_d)\n",
    "\n",
    "        # Initialize discriminator's optimizer\n",
    "        optimizer_d = torch.optim.Adam(params=filter(lambda p: p.requires_grad, discriminator.parameters()),\n",
    "                                       lr=lr)\n",
    "\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        generator = checkpoint['generator']\n",
    "        discriminator = checkpoint['discriminator']\n",
    "        optimizer_g = checkpoint['optimizer_g']\n",
    "        optimizer_d = checkpoint['optimizer_d']\n",
    "        print(\"\\nLoaded checkpoint from epoch %d.\\n\" % (checkpoint['epoch'] + 1))\n",
    "\n",
    "    # Truncated VGG19 network to be used in the loss calculation\n",
    "    truncated_vgg19 = TruncatedVGG19(i=vgg19_i, j=vgg19_j)\n",
    "    truncated_vgg19.eval()\n",
    "\n",
    "    # Loss functions\n",
    "    content_loss_criterion = nn.MSELoss()\n",
    "    adversarial_loss_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Move to default device\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    truncated_vgg19 = truncated_vgg19.to(device)\n",
    "    content_loss_criterion = content_loss_criterion.to(device)\n",
    "    adversarial_loss_criterion = adversarial_loss_criterion.to(device)\n",
    "\n",
    "    train_dataset = LowDataset()\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "    valid_dataset = LowDataset('valid')\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=workers, pin_memory=True)\n",
    "    epochs = int(iterations // len(train_loader) + 1)\n",
    "\n",
    "    # Total number of epochs to train for\n",
    "    epochs = int(iterations // len(train_loader) + 1)\n",
    "\n",
    "    # Epochs\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "\n",
    "        # At the halfway point, reduce learning rate to a tenth\n",
    "        if epoch == int((iterations / 2) // len(train_loader) + 1):\n",
    "            adjust_learning_rate(optimizer_g, 0.1)\n",
    "            adjust_learning_rate(optimizer_d, 0.1)\n",
    "\n",
    "        # One epoch's training\n",
    "        train(train_loader=train_loader,\n",
    "              generator=generator,\n",
    "              discriminator=discriminator,\n",
    "              truncated_vgg19=truncated_vgg19,\n",
    "              content_loss_criterion=content_loss_criterion,\n",
    "              adversarial_loss_criterion=adversarial_loss_criterion,\n",
    "              optimizer_g=optimizer_g,\n",
    "              optimizer_d=optimizer_d,\n",
    "              epoch=epoch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'generator': generator,\n",
    "                    'discriminator': discriminator,\n",
    "                    'optimizer_g': optimizer_g,\n",
    "                    'optimizer_d': optimizer_d},\n",
    "                   'checkpoint_srgan.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/50]----Batch Time 34.849 (34.849)----Data Time 1.597 (1.597)----Cont. Loss 0.4133 (0.4133)----Adv. Loss 0.7020 (0.7020)----Disc. Loss 1.3754 (1.3754)\n",
      "Epoch: [0][4/50]----Batch Time 30.008 (29.912)----Data Time 0.002 (0.321)----Cont. Loss 0.3448 (0.3886)----Adv. Loss 2.7912 (1.4927)----Disc. Loss 0.1804 (0.8352)\n",
      "Epoch: [0][8/50]----Batch Time 30.017 (29.852)----Data Time 0.002 (0.179)----Cont. Loss 0.3341 (0.3485)----Adv. Loss 6.8091 (3.5958)----Disc. Loss 0.0088 (0.5081)\n",
      "Epoch: [0][12/50]----Batch Time 26.352 (28.861)----Data Time 0.002 (0.125)----Cont. Loss 0.2724 (0.3321)----Adv. Loss 3.6933 (4.2206)----Disc. Loss 0.1322 (0.3726)\n",
      "Epoch: [0][16/50]----Batch Time 26.796 (28.323)----Data Time 0.002 (0.096)----Cont. Loss 0.2936 (0.3234)----Adv. Loss 8.4406 (4.7674)----Disc. Loss 0.0481 (0.2942)\n",
      "Epoch: [0][20/50]----Batch Time 27.037 (27.974)----Data Time 0.002 (0.078)----Cont. Loss 0.3545 (0.3212)----Adv. Loss 7.8449 (5.4766)----Disc. Loss 0.0177 (0.2456)\n",
      "Epoch: [0][24/50]----Batch Time 26.447 (27.757)----Data Time 0.002 (0.066)----Cont. Loss 0.2863 (0.3203)----Adv. Loss 13.7766 (6.2846)----Disc. Loss 0.0064 (0.2138)\n",
      "Epoch: [0][28/50]----Batch Time 26.142 (27.565)----Data Time 0.002 (0.057)----Cont. Loss 0.3191 (0.3209)----Adv. Loss 10.4490 (7.1573)----Disc. Loss 0.0019 (0.1862)\n",
      "Epoch: [0][32/50]----Batch Time 27.843 (27.470)----Data Time 0.002 (0.050)----Cont. Loss 0.3174 (0.3253)----Adv. Loss 11.8333 (7.2885)----Disc. Loss 0.0024 (0.1675)\n",
      "Epoch: [0][36/50]----Batch Time 25.535 (27.283)----Data Time 0.002 (0.045)----Cont. Loss 0.4002 (0.3284)----Adv. Loss 3.7644 (7.4894)----Disc. Loss 0.5659 (0.1675)\n",
      "Epoch: [0][40/50]----Batch Time 24.752 (27.057)----Data Time 0.002 (0.041)----Cont. Loss 0.3591 (0.3322)----Adv. Loss 11.6274 (7.9846)----Disc. Loss 0.0022 (0.1738)\n",
      "Epoch: [0][44/50]----Batch Time 24.944 (26.827)----Data Time 0.002 (0.037)----Cont. Loss 0.3896 (0.3334)----Adv. Loss 9.0253 (7.9805)----Disc. Loss 0.0052 (0.1747)\n",
      "Epoch: [0][48/50]----Batch Time 24.275 (26.674)----Data Time 0.002 (0.034)----Cont. Loss 0.2704 (0.3305)----Adv. Loss 3.1736 (7.8967)----Disc. Loss 0.4158 (0.1780)\n",
      "Epoch: [1][0/50]----Batch Time 30.708 (30.708)----Data Time 1.583 (1.583)----Cont. Loss 0.2847 (0.2847)----Adv. Loss 12.7797 (12.7797)----Disc. Loss 0.1309 (0.1309)\n",
      "Epoch: [1][4/50]----Batch Time 25.190 (27.048)----Data Time 0.002 (0.318)----Cont. Loss 0.3403 (0.3269)----Adv. Loss 5.9228 (8.0907)----Disc. Loss 0.0799 (0.1609)\n",
      "Epoch: [1][8/50]----Batch Time 24.824 (26.091)----Data Time 0.002 (0.177)----Cont. Loss 0.3820 (0.3274)----Adv. Loss 2.5944 (8.3268)----Disc. Loss 0.8807 (0.2988)\n",
      "Epoch: [1][12/50]----Batch Time 24.791 (25.739)----Data Time 0.002 (0.123)----Cont. Loss 0.3278 (0.3280)----Adv. Loss 11.3910 (8.6373)----Disc. Loss 0.0627 (0.2185)\n",
      "Epoch: [1][16/50]----Batch Time 25.878 (25.598)----Data Time 0.003 (0.095)----Cont. Loss 0.3295 (0.3345)----Adv. Loss 10.3377 (8.4043)----Disc. Loss 0.0114 (0.2014)\n",
      "Epoch: [1][20/50]----Batch Time 24.672 (25.514)----Data Time 0.002 (0.077)----Cont. Loss 0.4045 (0.3314)----Adv. Loss 13.9195 (9.5361)----Disc. Loss 0.0049 (0.1707)\n",
      "Epoch: [1][24/50]----Batch Time 25.170 (25.433)----Data Time 0.002 (0.065)----Cont. Loss 0.3955 (0.3387)----Adv. Loss 6.8561 (9.4197)----Disc. Loss 0.0229 (0.1491)\n",
      "Epoch: [1][28/50]----Batch Time 25.882 (25.415)----Data Time 0.002 (0.056)----Cont. Loss 0.2936 (0.3383)----Adv. Loss 9.5302 (9.0207)----Disc. Loss 0.0061 (0.1446)\n",
      "Epoch: [1][32/50]----Batch Time 25.559 (25.523)----Data Time 0.002 (0.050)----Cont. Loss 0.2993 (0.3347)----Adv. Loss 10.9239 (9.3681)----Disc. Loss 0.0020 (0.1310)\n",
      "Epoch: [1][36/50]----Batch Time 25.933 (25.532)----Data Time 0.002 (0.045)----Cont. Loss 0.2941 (0.3335)----Adv. Loss 8.5812 (9.1585)----Disc. Loss 0.0094 (0.1195)\n",
      "Epoch: [1][40/50]----Batch Time 25.235 (25.546)----Data Time 0.002 (0.040)----Cont. Loss 0.2717 (0.3271)----Adv. Loss 8.0290 (9.1161)----Disc. Loss 0.0111 (0.1095)\n",
      "Epoch: [1][44/50]----Batch Time 24.466 (25.473)----Data Time 0.002 (0.037)----Cont. Loss 0.3184 (0.3262)----Adv. Loss 13.7695 (9.1305)----Disc. Loss 0.5282 (0.1171)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
